{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9403358,"sourceType":"datasetVersion","datasetId":5708585},{"sourceId":9403512,"sourceType":"datasetVersion","datasetId":5708721},{"sourceId":9403655,"sourceType":"datasetVersion","datasetId":5708834}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q tiktoken verovio","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:16:51.328719Z","iopub.execute_input":"2024-09-15T14:16:51.329114Z","iopub.status.idle":"2024-09-15T14:17:05.901068Z","shell.execute_reply.started":"2024-09-15T14:16:51.329076Z","shell.execute_reply":"2024-09-15T14:17:05.899711Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('ucaslcl/GOT-OCR2_0', trust_remote_code=True)\nmodel = AutoModel.from_pretrained('ucaslcl/GOT-OCR2_0', trust_remote_code=True, low_cpu_mem_usage=True, device_map='cuda', use_safetensors=True, pad_token_id=tokenizer.eos_token_id)\nmodel = model.eval().cuda()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-15T14:17:09.095169Z","iopub.execute_input":"2024-09-15T14:17:09.095622Z","iopub.status.idle":"2024-09-15T14:17:22.621111Z","shell.execute_reply.started":"2024-09-15T14:17:09.095579Z","shell.execute_reply":"2024-09-15T14:17:22.619916Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"got_vision_b.py:   0%|          | 0.00/16.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2508a3b5c4e45788bc67ae551c58b19"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ucaslcl/GOT-OCR2_0:\n- got_vision_b.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"render_tools.py:   0%|          | 0.00/1.99k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69d3f1e3f89543faad154e53366fa8e9"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ucaslcl/GOT-OCR2_0:\n- render_tools.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/ucaslcl/GOT-OCR2_0:\n- got_vision_b.py\n- render_tools.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.43G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36d99cf763a24346a43907b8aed1fdd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d58f9ded03e543a5b3e8ad4e4d5fbf5c"}},"metadata":{}}]},{"cell_type":"code","source":"%ls ../input/test-ocr/","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:43:22.165205Z","iopub.execute_input":"2024-09-15T14:43:22.165622Z","iopub.status.idle":"2024-09-15T14:43:23.216273Z","shell.execute_reply.started":"2024-09-15T14:43:22.165582Z","shell.execute_reply":"2024-09-15T14:43:23.215076Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Test1.jpg   Test11.jpg  Test13.jpg  Test2.jpg  Test4.jpg  Test6.jpg  Test8.jpg\nTest10.jpg  Test12.jpg  Test14.jpg  Test3.jpg  Test5.jpg  Test7.jpg  Test9.jpg\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings \nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:43:23.772190Z","iopub.execute_input":"2024-09-15T14:43:23.772585Z","iopub.status.idle":"2024-09-15T14:43:23.777505Z","shell.execute_reply.started":"2024-09-15T14:43:23.772549Z","shell.execute_reply":"2024-09-15T14:43:23.776605Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# OCR","metadata":{}},{"cell_type":"code","source":"# input your test image\npath= \"../input/test-ocr/\"\nimage_file = path+'Test1.jpg'\n# plain texts OCR\nres = model.chat(tokenizer, image_file, ocr_type='ocr')\nprint(res)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:43:32.565288Z","iopub.execute_input":"2024-09-15T14:43:32.566177Z","iopub.status.idle":"2024-09-15T14:43:57.005256Z","shell.execute_reply.started":"2024-09-15T14:43:32.566135Z","shell.execute_reply":"2024-09-15T14:43:57.004278Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Haoran Wei1,*, Chenglong Liu3,*, Jinyue Chen3, Jia Wang1, Lingyu Kong3, Yanming Xu1, \nZheng Ge1, Liang Zhao1, Jianjian Sun1, Yuang Peng4, Chunrui Han2, Xiangyu Zhang1,2 \n1StepFun 2Megvii Technology \n3University of Chinese Academy of Sciences 4Tsinghua University \nhttps://github.com/Ucas-HaoranWei/GOT-OCR2.0 \n \n \nAbstract \n \nTraditional OCR systems (OCR-1.0) are increasingly unable to meet people’s \nusage due to the growing demand for intelligent processing of man-made optical \ncharacters.  In this paper, we collectively refer to all artificial optical signals \n(e.g., plain texts, math/molecular formulas, tables, charts, sheet music, and even \ngeometric shapes) as \"characters\" and propose the General OCR Theory along with \nan excellent model, namely GOT, to promote the arrival of OCR-2.0. The GOT, \nwith 580M parameters, is a unified, elegant, and end-to-end model, consisting of \na high-compression encoder and a long-contexts decoder. As an OCR-2.0 model, \nGOT can handle all the above \"characters\" under various OCR tasks.  On the \ninput side, the model supports commonly used scene- and document-style images \nin slice and whole-page styles.  On the output side, GOT can generate plain or \nformatted results (markdown/tikz/smiles/krn) via an easy prompt. Besides, the \nmodel enjoys interactive OCR features, i.e., region-level recognition guided by \ncoordinates or colors. Furthermore, we also adapt dynamic resolution and multi-\npage OCR technologies to GOT for better practicality. In experiments, we provide \nsufficient results to prove the superiority of our model. \n \n1 Introduction \n \nOptical Character Recognition (OCR) is a widely used technology that extracts the characters \nembedded in an optical image into an editable format. Typical OCR systems [10] in the OCR-1.0 era \nare mainly designed based on a multi-modular pipeline style, commonly including element detection, \nregion cropping, and character recognition parts. Each module is prone to falling into local optima, \nmaking the whole system incur high maintenance costs. Moreover, traditional OCR methods have \ninsufficient general ability, reflected as different OCR-1.0 networks usually designed for different \nsub-tasks.  Nevertheless, choosing a suitable one from diverse OCR models for a special task is \nalways inconvenient for users. \n \nIn the past year, Large Vision Language models (LVLMs) [5, 9, 24, 27, 36, 46, 49] have developed \nrapidly and showcased impressive performance. As a highly anticipated ability, the OCR performance \nof current VLMs is continuously improving. Based on CLIP [37], LLaVA [24] naturally acquires \nthe English OCR ability after the instruct tuning phase. To lift the OCR accuracy and support other \nlanguages, e.g., Chinese, Qwen-VL [5] unfreezes its image encoder (a CLIP-G) and uses lots of \nOCR data in its stage-two training.  Innovatively, Vary [46] generates a new high-resolution OCR \nvision vocabulary paralleling the CLIP branch to deal with document-level dense OCR. By contrast,\n","output_type":"stream"}]},{"cell_type":"code","source":"image_file = path+'Test2.jpg'\n# plain texts OCR\nres = model.chat(tokenizer, image_file, ocr_type='ocr')\nprint(res)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:43:57.006838Z","iopub.execute_input":"2024-09-15T14:43:57.007157Z","iopub.status.idle":"2024-09-15T14:44:01.814145Z","shell.execute_reply.started":"2024-09-15T14:43:57.007124Z","shell.execute_reply":"2024-09-15T14:44:01.813147Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"An a Hempt to get more in for motion about the Adm in ral ty house mei ting will be mede in the house& Commons this afternoon. Labor wr M. P. s are cody have many pue sti ong to the Prime Him is teros tii ng for e to te met. P re sid ent k emu d yle ve from lou ol on A in pot lest miel t to or ie in We sl in gt on this mor mino y. He is to make e 30- minute motion- wide or oed cast and television zep oot on his\n","output_type":"stream"}]},{"cell_type":"code","source":"image_file = path+'Test3.jpg'\n# plain texts OCR\nres = model.chat(tokenizer, image_file, ocr_type='ocr')\nprint(res)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:44:01.815422Z","iopub.execute_input":"2024-09-15T14:44:01.815801Z","iopub.status.idle":"2024-09-15T14:44:03.550514Z","shell.execute_reply.started":"2024-09-15T14:44:01.815766Z","shell.execute_reply":"2024-09-15T14:44:03.549552Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"A my Thomas 2.  Che lae a Cook 3.  Joel Ny lune KT M TAYLOR 5.  Dais\n","output_type":"stream"}]},{"cell_type":"code","source":"image_file = path+'Test4.jpg'\nres = model.chat(tokenizer, image_file, ocr_type='ocr', ocr_box='')\nprint(res)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:44:03.552413Z","iopub.execute_input":"2024-09-15T14:44:03.552766Z","iopub.status.idle":"2024-09-15T14:44:04.457177Z","shell.execute_reply.started":"2024-09-15T14:44:03.552732Z","shell.execute_reply":"2024-09-15T14:44:04.456221Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"HEROES Skittles\n","output_type":"stream"}]},{"cell_type":"code","source":"image_file = path+'Test4.jpg'\nres = model.chat(tokenizer, image_file, ocr_type='format', ocr_box='')\nprint(res)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:44:04.458433Z","iopub.execute_input":"2024-09-15T14:44:04.458812Z","iopub.status.idle":"2024-09-15T14:44:05.392312Z","shell.execute_reply.started":"2024-09-15T14:44:04.458776Z","shell.execute_reply":"2024-09-15T14:44:05.391367Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\\text{HEROES}\n","output_type":"stream"}]},{"cell_type":"code","source":"image_file = path+'Test6.jpg'\nres = model.chat(tokenizer, image_file, ocr_type='ocr', ocr_box='')\nprint(res)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:35:01.934526Z","iopub.execute_input":"2024-09-15T14:35:01.935415Z","iopub.status.idle":"2024-09-15T14:35:02.989712Z","shell.execute_reply.started":"2024-09-15T14:35:01.935375Z","shell.execute_reply":"2024-09-15T14:35:02.988818Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"OX XO OX XO\n","output_type":"stream"}]},{"cell_type":"code","source":"image_file = path+'Test7.jpg'\nres = model.chat(tokenizer, image_file, ocr_type='ocr')\nprint(res)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:44:27.654707Z","iopub.execute_input":"2024-09-15T14:44:27.655374Z","iopub.status.idle":"2024-09-15T14:44:28.809387Z","shell.execute_reply.started":"2024-09-15T14:44:27.655337Z","shell.execute_reply":"2024-09-15T14:44:28.808306Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"TARON GA·  ZOOLOGICAL PARK\n","output_type":"stream"}]},{"cell_type":"code","source":"image_file = path+'Test8.jpg'\nres = model.chat(tokenizer, image_file, ocr_type='ocr')\nprint(res)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:44:29.960678Z","iopub.execute_input":"2024-09-15T14:44:29.961580Z","iopub.status.idle":"2024-09-15T14:44:34.258594Z","shell.execute_reply.started":"2024-09-15T14:44:29.961537Z","shell.execute_reply":"2024-09-15T14:44:34.257597Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"B HV N Ver di per stat Acute Treatment of Migraine Ver di per stat Preventive Treatment of Migraine Tr or ilu z ole Acute and Preventive Migraine Tr or ilu z ole Lung Inflammation C OVID- 19 Drug Tr or ilu z ole Alzheimer' s Disease Zave ge pant OCD Zave ge pant Spinocerebellar Ataxia Rime ge pant Multiple System Atrophy Rime ge pant Amyotrophic Lateral Sclerosis Pre- clinical Phase I Phase Il Phase Il l Approved\n","output_type":"stream"}]},{"cell_type":"code","source":"image_file = path+'Test9.jpg'\nres = model.chat(tokenizer, image_file, ocr_type='ocr')\nprint(res)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:44:34.569552Z","iopub.execute_input":"2024-09-15T14:44:34.569960Z","iopub.status.idle":"2024-09-15T14:44:38.934534Z","shell.execute_reply.started":"2024-09-15T14:44:34.569923Z","shell.execute_reply":"2024-09-15T14:44:38.933574Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"San Francisco salaries, USD thousand Base Pay Overtime Pay Other Pay Benefits 319 61 90 As st Med Examiner 270 68 72 Lieutenant, Fire Suppression 129 221 13 44 Battalion Chief, Fire Suppress 186 131 30 57 273 24 39 66 As st Med Examiner 100 200 300 400 500\n","output_type":"stream"}]},{"cell_type":"code","source":"image_file = path+'Test10.jpg'\nres = model.chat(tokenizer, image_file, ocr_type='ocr')\nprint(res)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:44:45.063908Z","iopub.execute_input":"2024-09-15T14:44:45.064625Z","iopub.status.idle":"2024-09-15T14:44:59.916716Z","shell.execute_reply.started":"2024-09-15T14:44:45.064583Z","shell.execute_reply":"2024-09-15T14:44:59.915756Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Emperor Penguin The emperor penguin is the tallest and heaviest of all living penguin species.  Appearance Emperor penguins appearance can vary based on their age or the time of year.  Generally, adult penguins can stond up to 110-130 cm tall and weigh between 22.7 and 45.4 kg, with moles weighing more than females. Like all penguin species, emperor penguins have streamlined bodies and wings that are more like stiff, flat flippers.  Males and females are similar in size and colour. The adult has block dorsal feathers that cover their head and back area. The under parts of the wings and belly are white. In juveniles, the chin and throat are white while their bills are black. Emperor penguin chicks are typically covered with silver- grey dow m and have block heads and white masks.  Diet Emperor penguins are generally consistent in what they eat. Their diet consists mainly of fish, crustaceans and cephalopods. Fish are usually the most important food source with the Antarctic silverfish making up the bulk of their diet. Other prey include squid and or ill. The emperor penguin searches for food in the open water of the Southern Ocean in either ice free areas of open water or tidal crocks in pack ice. They can dive around 50 m to catch fish, repeating this sequence about six times before surfacing to breathe.  Habitat The emperor penguin can generally be found in a very specific location.  They are found almost exclusively in the Antarctic circle and almost always breed on stable pack ice near the coast. Breeding colonies are usually located in areas where ice cliffs and icebergs shelter them from the wind. Since 2009, a number of colonies have been reported on shelf ice rather than sea ice. In some cases, they have moved to shelf ice when sea ice forms later.  In 2012 the emperor penguin was up listed from a species of least concern to nearly threatened. The primary reason for this is due to declining food availability as a result of climate change and industrial fishing.\n","output_type":"stream"}]},{"cell_type":"code","source":"image_file = path+'Test11.jpg'\nres = model.chat(tokenizer, image_file, ocr_type='ocr')\nprint(res)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:45:08.236053Z","iopub.execute_input":"2024-09-15T14:45:08.237016Z","iopub.status.idle":"2024-09-15T14:45:31.167847Z","shell.execute_reply.started":"2024-09-15T14:45:08.236970Z","shell.execute_reply":"2024-09-15T14:45:31.166918Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"• End-to-end. Compared to OCR-1.0 models with complex procedures, the OCR-2.0 model should\nenjoy a unified and end-to-end architecture to ensure lower maintenance costs. It is cool that a\nbeginner can quickly master the entire OCR system in the 2.0 era.\n• Low training and inference costs. The OCR-2.0 model should not be a chatbot, like LVLM, that\nfocuses on reasoning tasks. Its focus should be on strong perception and recognition of optical\ncharacters, so it needs a reasonable number of model parameters in exchange for lower training\nand inference costs.\n• Versatility. The OCR-2.0 model’s other important point is versatility, including recognizing more\ngeneral artificial optical “characters”, e.g., sheet music, charts, geometric shapes, etc. Besides, the\nmodel should support the output format with stronger readability, e.g., LATEX/Markdown format for\nformulas and tables.\nBased on the proposed general OCR theory, we present a primary OCR-2.0 model (GOT) to bridge\nthe gap between OCR-1.0 models and people’s higher optical character processing demands. In\narchitecture, we adopt the unsophisticated encoder-decoder paradigm for the model. Specifically,\nGOT enjoys a high compression rate encoder to transfer the optical image to tokens as well as a\nlong context length decoder to output the corresponding OCR results. The encoder has approx-\nimately 80M parameters posing 1024×1024 input size which is enough to deal with commonly\nused photo/document input styles. Each input image will be compressed to tokens with 256×1024\ndimensions. The decoder of GOT, with 0.5B parameters, supports 8K max length tokens to ensure\nit can tackle long-context scenarios. We devise an effective and efficient training strategy for GOT,\nwhich can be divided into three procedures, i.e., decoupled pre-training of the encoder, joint-training\nof the encoder with a new decoder, and further post-training of the decoder. Besides, to further lift\nthe practicality of GOT, we additionally adapt the fine-grained OCR feature for better interactivity,\ndynamic resolution strategy for ultra-high-resolution images (e.g., over 2K), and the multi-page OCR\ntechnology to alleviate the problem of difficulty in breaking pages in PDF image-text pairs (e.g.,\npage breaks in .tex files). To support each training stage, we do many data engines for synthetic data\nproduction, which is the key to the success of GOT and will be described in detail in this paper. The\nmain input data format supported by our model can be seen in Figure 1.\nAs a model for envisioning OCR-2.0, GOT demonstrates promising performance in our experiments\nin various OCR tasks. We hope the proposed simple and elegant GOT can draw more researchers to\ninvest in the research of OCR-2.0. Of course, the path to OCR-2.0 is still long and GOT also enjoys\nmuch improvement room, such as supporting more languages, more general artificial signals, and\nmore complex geometries. In this new era led by LVLMs, we are convinced that the pure OCR model\nis not over, it may even be a new beginning.\n","output_type":"stream"}]},{"cell_type":"code","source":"image_file = path+'Test12.jpg'\nres = model.chat(tokenizer, image_file, ocr_type='ocr')\nprint(res)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:45:38.214060Z","iopub.execute_input":"2024-09-15T14:45:38.214925Z","iopub.status.idle":"2024-09-15T14:45:40.001586Z","shell.execute_reply.started":"2024-09-15T14:45:38.214887Z","shell.execute_reply":"2024-09-15T14:45:40.000671Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Person Height Wendy 5'6\"  Michael 5'9\"  Rachael 5'3\"  Allen 5'11\"\n","output_type":"stream"}]},{"cell_type":"code","source":"image_file = path+'Test13.jpg'\nres = model.chat(tokenizer, image_file, ocr_type='ocr')\nprint(res)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:45:52.323365Z","iopub.execute_input":"2024-09-15T14:45:52.324368Z","iopub.status.idle":"2024-09-15T14:45:56.406838Z","shell.execute_reply.started":"2024-09-15T14:45:52.324326Z","shell.execute_reply":"2024-09-15T14:45:56.405894Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Om g! You' ll never guess who I just ran into I was at the coffee shop by work standing off to the side waiting for my iced coffee and bagel and the place was EMPTY And then, like a damn scene from a movie, the door whooshes open and reveals. . .  MJ! ! ! !  We locked eyes immediately and burst out laughing and then spent like 15 mins catching up He' s doing so well! He asked about you: ' )\n","output_type":"stream"}]},{"cell_type":"code","source":"image_file = path+'Test14.jpg'\nres = model.chat(tokenizer, image_file, ocr_type='ocr')\nprint(res)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T14:46:05.875460Z","iopub.execute_input":"2024-09-15T14:46:05.876125Z","iopub.status.idle":"2024-09-15T14:46:11.552332Z","shell.execute_reply.started":"2024-09-15T14:46:05.876083Z","shell.execute_reply":"2024-09-15T14:46:11.551359Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"There is nothing after NO 2:48 PM.  What' ll u see 2:48 PM.  2:48 PM.  I will find something that you need 2:48 PM.  Much more than a gift of course 2:48 PM.  I dk who' s going to win this debate 2:49 PM.  2:49 PM.  Looks like. . . m loosing 2:49 PM.  But. . . hum shehens hah hai. . ya ad rak hn a 2:50 P. M.  Sorry baz i gar 2:50 P. M.  Type a message\n","output_type":"stream"}]}]}